# LLMTheory
这是一个大模型的实战项目，介绍一些大模型方面的知识，包括但不限于BERT，Transformer，RoBERT，Attention机制等。

Class1：
介绍一下注意力机制的原理与QKV的计算，并附上代码实现的详细过程
**https://github.com/Enermy/LLMTheory/tree/main/Class1-Attention**

Class2：
动手实现Transformer的代码，并使用该模型来实现一个简单的机器翻译任务
https://github.com/Enermy/LLMTheory/tree/main/Class2
